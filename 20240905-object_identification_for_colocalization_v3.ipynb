{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7c3c06",
   "metadata": {},
   "source": [
    "# Trace blobs (e.g. nuclei, cells, ...) over the z-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06259e5",
   "metadata": {},
   "source": [
    "Code written by Nathan De Fruyt (nathan.defruyt@kuleuven.be, nathan.defruyt@gmail.com). \n",
    "\n",
    "The algorithm is simple, but functional for minimal goals:\n",
    "1. **version 3 edit:** instead of blob recognition, I threshold on the percentile of I values (i.e. also intrinsic background correction)\n",
    "1. **version 4 edit:** splitting blobs that are larger than normal (95% percentile?)\n",
    "1. **version 5 edit:** still to figure out splitting, but already 3D image labeling + better thresholding\n",
    "1. **version 6 edit:** segment anything algorithm instead of skimage\n",
    "\n",
    "* next, I deviated from Wim's advice and went on to work with the blob's \n",
    "    1. **center coordinates\n",
    "    1. **mean intensity value\n",
    "    1. **radius** (restricted to 20 pixels, as this appeared to be towards the higher end of nucleus radii -- adapt this!)\n",
    "\n",
    "To this, the program:\n",
    "1. determines **common blob labels** based on how near they are (max displacement of center = 10 pixels in x/y direction, max rise of 5 planes)\n",
    "1. renders one line per blob for the plane with the **highest intensity value**\n",
    "\n",
    "Each step (1. blob identification, 2. blob labelling, 3. summary) are rendered in separate .csv files. \n",
    "Blob identification takes the longest (a few hours for a day of pictures). The subseding steps are fast.\n",
    "\n",
    "**Parameters can therefore be adapted** in the second and third step without consideration. \n",
    "\n",
    "Do think about changing parameters to the first step.\n",
    "\n",
    "___Questions are welcome, optimization of the algorithm too.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## general math and system modules/functions\n",
    "from math import sqrt, atan, tan, cos, sin\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tqdm import tqdm\n",
    "import shutil as sh\n",
    "from lxml import etree ## for parsing html (for the metadata)\n",
    "\n",
    "## parallellization!\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "## data formatting and parsing!\n",
    "import pandas as pd\n",
    "from html5lib import *\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "## image import and processing module functions\n",
    "import czifile as cfile\n",
    "from skimage import data, data, measure, exposure\n",
    "from skimage.measure import label, regionprops_table, regionprops\n",
    "from skimage.morphology import closing\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, laplace, threshold_otsu\n",
    "import cv2 as cv\n",
    "import PIL\n",
    "import tifffile as tf\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import string\n",
    "\n",
    "## plotting modules\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05888dd0",
   "metadata": {},
   "source": [
    "## 1. Find data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ebb3a",
   "metadata": {},
   "source": [
    "First I adapted some existing functions to more easily check and handle data either here in jupyter notebook or to the purpose of an application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e32bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2tif(img, file, pixelsizes, pixelunits, channels): \n",
    "    tf.imwrite(file,\n",
    "              img,\n",
    "              bigtiff = False,\n",
    "              photometric = 'rgb',\n",
    "              planarconfig = 'separate', \n",
    "              metadata = {\n",
    "                  'axes': 'TCZYXS',\n",
    "                  'SignificantBits': 8,\n",
    "                  'PhysicalSizeX': pixelsizes[0],\n",
    "                  'PhysicalSizeXUnit': pixelunits[0],\n",
    "                  'PhysicalSizeY': pixelsizes[1],\n",
    "                  'PhysicalSizeYUnit': pixelunits[1],\n",
    "                  'PhysicalSizeZ': pixelsizes[2],\n",
    "                  'PhysicalSizeZUnit': pixelunits[2],\n",
    "                  'Channel': {'Name': channels},\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb10ea9",
   "metadata": {},
   "source": [
    "## 2. Render ___summary___ (mean, max, ...) intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd3668",
   "metadata": {},
   "source": [
    "I want to make the process automated for each picture in the folder.\n",
    "1. __load__ the file\n",
    "1. __extract__ the channels (gfp and bfp in my case)\n",
    "1. __threshold and detect__ nuclei in the gfp channel\n",
    "1. extract object __features__ (including intensity, area, coordinates, and radius)\n",
    "1. threshold on object __radius__\n",
    "\n",
    "For all these things, I'd like to save (per pictures): \n",
    "1. the object __features__ (for all objects)\n",
    "1. also include the __intensity__ in the other channels\n",
    "1. possibly recognize whether the nucleus is fully __contained__ by the marker (e.g. nucleus in BAG)\n",
    "1. save a __tif__ with the labeled nuclei in one channel, the original gfp values in the other channel and the bfp in yet another channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f50cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_nuclei(channel1, channel2, sigma = 7, threshold1 = 99.6, threshold2 = 99.6, min_radius = 10, max_radius = 35, max_ratio = 3):\n",
    "    \n",
    "    ## 1) process/quantify image channel 1 - the nuclearly localized channel:\n",
    "    \n",
    "        ## take laplacian of the gaussian of the image - make sigma wide enough for good smoothing\n",
    "    img1_lp = laplace(gaussian(channel1, sigma = sigma))\n",
    "\n",
    "        ## threshold on percentile - very strict, yet slightly permissive threshold of 99.8\n",
    "    thresh1 = np.percentile(img1_lp, threshold1)\n",
    "    img1_bw = np.zeros(img1_lp.shape)\n",
    "    img1_bw[img1_lp > thresh1] = 1\n",
    "\n",
    "        ## close the edges and label adhering regions\n",
    "#     img_cls = closing(img_bw)\n",
    "#     img_lbl = label(img_cls)\n",
    "    img1_lbl = label(img1_bw)\n",
    "    \n",
    "        ## subtract the background from the image (everything that's below the threshold is considered background)\n",
    "    bg1 = np.mean(img1_lp < thresh1)\n",
    "    img1_bg = channel1 - bg1\n",
    "    img1_bg[img1_bg < 0] = 0\n",
    "    print(f'    Thresholded green channel on intensity percentile (P{threshold1})')\n",
    "    \n",
    "        ## extract object features\n",
    "    idf1 = pd.DataFrame(regionprops_table(label_image=img1_lbl, intensity_image=img1_bg, properties = ('label', 'intensity_mean', 'centroid', 'bbox', 'area')))\n",
    "        ## relabel columns\n",
    "    idf1 = idf1.rename(columns = {'label': \"ID\", 'intensity_mean': \"I\", 'area': \"area\", 'centroid-0': \"z\", 'centroid-1': \"y\", 'centroid-2': \"x\", 'bbox-0': \"zmin\", 'bbox-1': \"ymin\", 'bbox-2': \"xmin\", 'bbox-3': \"zmax\", 'bbox-4': \"ymax\", 'bbox-5': \"xmax\"})\n",
    "        ## calculate radius\n",
    "    idf1['r'] = list(map(lambda x: np.cbrt(3*x/(4*np.pi)), idf1['area']))\n",
    "        ## calculate axes\n",
    "    idf1['r_z'] = xyzsize[2] * (idf1['zmax'] - idf1['zmin'])\n",
    "    idf1['r_y'] = xyzsize[1] * (idf1['ymax'] - idf1['ymin'])\n",
    "    idf1['r_x'] = xyzsize[0] * (idf1['xmax'] - idf1['xmin'])\n",
    "        ## compute a ratio as a proxy for eccentricity (major axis/minor axis)\n",
    "    def r_ratio(lbl):\n",
    "        sub = list(idf1.loc[idf1['ID'] == lbl, ['r_z', 'r_y', 'r_x']].iloc[0, :])\n",
    "        return float(max(sub)/min(sub))\n",
    "    idf1['r_ratio'] = list(map(r_ratio, idf1['ID']))\n",
    "    print(f'    Calculated object intensity and shape features')\n",
    "        ## calculate max area - we assume spherical object and semi-spherical objects (sometimes cells are merges...)\n",
    "#     max_area = (4/3)*np.pi*(max_radius**3)\n",
    "#     min_area = (4/3)*np.pi(*min_radius**3)\n",
    "    \n",
    "        ## now threshold objects on shape (nuclei can only be three times as long as they are wide)\n",
    "    valid_nuclei = idf1[idf1['ID'].isin(idf1.ID[(idf1['r'] > min_radius) & (idf1['r'] < max_radius)])] ## first on radius\n",
    "    valid_nuclei = valid_nuclei[valid_nuclei['ID'].isin(idf1.ID[(idf1['r_ratio'] < max_ratio)])] ## then on shape\n",
    "    img1_selected = img1_lbl.copy()\n",
    "    img1_selected[np.isin(img1_selected, valid_nuclei['ID'], invert = True)] = 0\n",
    "    print(f'    Thresholded objects on radius ({min_radius} < r < {max_radius} and shape (min radius/max radius ratio = {max_ratio})')\n",
    "    ## 2) threshold channel 2 - the marker channel:\n",
    "    \n",
    "        ## 'smooth'\n",
    "    img2_lp = laplace(gaussian(channel2, sigma = sigma))\n",
    "    \n",
    "        ## threshold on percentile\n",
    "    thresh2 = np.percentile(img2_lp, threshold2)\n",
    "    img2_bw = np.zeros(img2_lp.shape)\n",
    "    img2_bw[img2_lp > thresh2] = 1\n",
    "    \n",
    "    print(f'    Thresholded blue channel on intensity percentile (P{threshold2})')\n",
    "    \n",
    "    ## 3) calculate coexpression value\n",
    "\n",
    "        ## calculate the percentage of the object that shows above-threshold expression in both channels\n",
    "    object_labels = valid_nuclei['ID'].unique() ## summarize object labels to check\n",
    "    coexpr = img2_bw.copy() ## make a copy of channel2 (marker) above threshold expression\n",
    "    coexpr[img1_selected == 0] = 0 ## set all pixels that are not within nuclei to black\n",
    "    perc_coexpr = np.zeros(img1_selected.shape) ## initialize a new array to visualize coexpression percentages\n",
    "    valid_nuclei['p_coexpr'] = 0 ## initialize a column to store the coexpression percentages\n",
    "\n",
    "    for lbl in tqdm(object_labels): ## for each object\n",
    "            ## count the number of pixesl showing coexpression\n",
    "        nr_contained = np.sum(coexpr[img1_selected == lbl] > 0)\n",
    "            ## count the total number of pixels in the object\n",
    "        total_pxls = np.sum(img1_selected == lbl)\n",
    "            ## calculate the percentage\n",
    "        perc_coexpr[img1_selected == lbl] = nr_contained/total_pxls\n",
    "        valid_nuclei.loc[valid_nuclei['ID'] == lbl, ['p_coexpr']] = nr_contained/total_pxls\n",
    "\n",
    "    print(f'    Calculated coexpression values for all {len(object_labels)} objects')\n",
    "\n",
    "    ## return output\n",
    "    return img1_selected, perc_coexpr, valid_nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb22916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Read file (E:/PhD/confocal/confocal_data/20241024-PXXX_vX-PHX9311_DiI\\20241024-PXXX_vX-PHX9311_DiI.63x.7_1.czi) 1/3\n",
      "\n",
      "    Collected metadata\n",
      "    Thresholded green channel on intensity percentile (P99.5)\n",
      "    Calculated object intensity and shape features\n",
      "    Thresholded objects on radius (10 < r < 35 and shape (min radius/max radius ratio = 5)\n",
      "    Thresholded blue channel on intensity percentile (P99.6)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.24 GiB for an array with shape (253, 1820, 1820) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m bfp \u001b[38;5;241m=\u001b[39m imstacks[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, :imstacks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], :imstacks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m], :imstacks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m4\u001b[39m], \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m## green channel: identify and label nuclei, threshold on radius, and extract object features\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m gfp_selected, coexpr_nuclei, Idf \u001b[38;5;241m=\u001b[39m \u001b[43mquantify_nuclei\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgfp_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbfp_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_radius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_radius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_radius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_radius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m nr_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(gfp_selected)) \u001b[38;5;66;03m## just for following progress\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    ->> detected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnr_objects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nucleus-like objects\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mquantify_nuclei\u001b[1;34m(channel1, channel2, sigma, threshold1, threshold2, min_radius, max_radius, max_ratio)\u001b[0m\n\u001b[0;32m     66\u001b[0m coexpr \u001b[38;5;241m=\u001b[39m img2_bw\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m## make a copy of channel2 (marker) above threshold expression\u001b[39;00m\n\u001b[0;32m     67\u001b[0m coexpr[img1_selected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m## set all pixels that are not within nuclei to black\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m perc_coexpr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_selected\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## initialize a new array to visualize coexpression percentages\u001b[39;00m\n\u001b[0;32m     69\u001b[0m valid_nuclei[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_coexpr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m## initialize a column to store the coexpression percentages\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lbl \u001b[38;5;129;01min\u001b[39;00m tqdm(object_labels): \u001b[38;5;66;03m## for each object\u001b[39;00m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;66;03m## count the number of pixesl showing coexpression\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.24 GiB for an array with shape (253, 1820, 1820) and data type float64"
     ]
    }
   ],
   "source": [
    "## don't touch this cell!!\n",
    "\n",
    "## thresholding parameters\n",
    "gfp_threshold = 99.5\n",
    "bfp_threshold = 99.6\n",
    "min_radius = 10\n",
    "max_radius = 35\n",
    "max_ratio = 5\n",
    "sigma = 7\n",
    "\n",
    "### and set folder\n",
    "folder = filedialog.askdirectory()\n",
    "files = glob.glob(folder + '/*.czi')\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    ## read the file\n",
    "    imstacks = cfile.imread(file)\n",
    "    print(f'>> Read file ({file}) {i+1}/{len(files)}\\n')\n",
    "    \n",
    "    ## collect experimental metadata\n",
    "    meta = os.path.basename(file).split('-')\n",
    "    date = meta[0]\n",
    "    protocol = meta[1]\n",
    "    \n",
    "    submeta = meta[2][:-4].split('_')\n",
    "    strain = submeta[0]\n",
    "    cultivation = submeta[1]\n",
    "    replicate = int(submeta[2])\n",
    "    \n",
    "    ## collect resolution metadata\n",
    "    root = ET.fromstring(cfile.CziFile(file).metadata())\n",
    "        ## initialize lists\n",
    "    xyzsize = list()\n",
    "    xyzunit = list()\n",
    "    channels = list()\n",
    "        ## retrieve physical distances and units\n",
    "    for axis in root[0][4][2]:\n",
    "        for detail in axis:\n",
    "            if detail.tag == 'Value': xyzsize.append(float(detail.text))\n",
    "            if detail.tag == 'DefaultUnitFormat': xyzunit.append(detail.text)   \n",
    "        ## retrieve channels\n",
    "    for channel in root[0][5][0]:\n",
    "        channels.append(channel.attrib.get('Name'))\n",
    "    print(f'    Collected metadata')\n",
    "    \n",
    "    ## extract separate channels (here gfp and bfp)\n",
    "    gfp = imstacks[0, 0, :imstacks.shape[2], :imstacks.shape[3], :imstacks.shape[4], 0]\n",
    "    bfp = imstacks[0, 1, :imstacks.shape[2], :imstacks.shape[3], :imstacks.shape[4], 0]\n",
    "    \n",
    "    ## green channel: identify and label nuclei, threshold on radius, and extract object features\n",
    "    gfp_selected, coexpr_nuclei, Idf = quantify_nuclei(gfp, bfp, sigma = sigma, threshold1 = gfp_threshold, threshold2 = bfp_threshold, min_radius = min_radius, max_radius = max_radius, max_ratio = max_ratio)\n",
    "    nr_objects = len(np.unique(gfp_selected)) ## just for following progress\n",
    "    print(f'    ->> detected {nr_objects} nucleus-like objects')\n",
    "    \n",
    "    ## make a new folder to store the file in\n",
    "    newdir = folder + '/' + meta[2][:-4]\n",
    "    if not os.path.isdir(newdir): \n",
    "        os.makedirs(newdir)\n",
    "    \n",
    "    ## write the stack to a tif file\n",
    "    print(f'    Writing labeled nuclei channel to file\\n')\n",
    "    write2tif(gfp_selected,  newdir + '/labeled.tif', xyzsize, xyzunit, ['EGFP'])\n",
    "    print(f'    Writing BFP channel to file\\n')\n",
    "    write2tif(bfp,  newdir + '/BFP.tif', xyzsize, xyzunit, ['EBFP'])\n",
    "    print(f'    Writing GFP channel to file\\n')\n",
    "    write2tif(gfp,  newdir + '/GFP.tif', xyzsize, xyzunit, ['EGFP'])\n",
    "    print(f'    Writing coexpression channel to file\\n')\n",
    "    write2tif(coexpr_nuclei,  newdir + '/coexpression.tif', xyzsize, xyzunit, ['coexpression'])\n",
    "\n",
    "    ## write the quantification to a file:\n",
    "    Idf.to_csv(folder + '/' + os.path.basename(file)[:-4] + '_ObjectFeatures.csv')\n",
    "    \n",
    "    print(f'    Finished analysis for file {file}\\nFind your files in {newdir}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723930b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
